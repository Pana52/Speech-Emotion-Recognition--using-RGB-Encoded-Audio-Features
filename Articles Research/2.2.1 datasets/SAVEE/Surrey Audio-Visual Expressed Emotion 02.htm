<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><!-- InstanceBegin template="/Templates/No Sidebars.dwt" codeOutsideHTMLIsLocked="false" --><head>
<meta http-equiv="content-type" content="text/html; charset=windows-1252">
<!-- InstanceBeginEditable name="doctitle" -->
<title>Surrey Audio-Visual Expressed Emotion (SAVEE) Database</title>
<meta name="Description" content="Surrey Audio-Visual Expressed Emotion (SAVEE) Database">
<meta name="Keywords" content="SAVEE, audio-visual, multimodal, emotion, expression, affect, affective, classification, recognition, database">
<meta name="content-language" content="en-GB">
<link rel="icon" href="http://kahlan.eps.surrey.ac.uk/savee/images/FaceJK_icon.png" type="image/png">
<!-- InstanceEndEditable -->
<link href="Surrey%20Audio-Visual%20Expressed%20Emotion%20(SAVEE)%20Database_files/style.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="Surrey%20Audio-Visual%20Expressed%20Emotion%20(SAVEE)%20Database_files/jquery.min.js"></script>
<script type="text/javascript" src="Surrey%20Audio-Visual%20Expressed%20Emotion%20(SAVEE)%20Database_files/hoverIntent.js"></script>
<script type="text/javascript" src="Surrey%20Audio-Visual%20Expressed%20Emotion%20(SAVEE)%20Database_files/superfish.js"></script>
<script type="text/javascript" src="Surrey%20Audio-Visual%20Expressed%20Emotion%20(SAVEE)%20Database_files/supersubs.js"></script>
<script type="text/javascript"> 
    $(document).ready(function(){ 
        $("ul.sf-menu").supersubs({ 
            minWidth:    12,   // minimum width of sub-menus in em units 
            maxWidth:    27,   // maximum width of sub-menus in em units 
            extraWidth:  1     // extra width can ensure lines don't sometimes turn over 
                               // due to slight rounding differences and font-family 
        }).superfish();  // call supersubs first, then superfish, so that subs are 
                         // not display:none when measuring. Call before initialising 
                         // containing tabs for same reason. 
    }); 
</script>
<!-- InstanceBeginEditable name="head" -->
<!-- InstanceEndEditable -->
</head>
<body>
<div id="nav" class="container_12 rounded" style="text-align:center;">

<font size="+3"><font color="white">Surrey Audio-Visual Expressed Emotion (SAVEE) Database</font></font>
</div>

<div id="nav" class="container_12 rounded">
  <ul class="sf-menu">
    <li class="first-item"><a href="http://kahlan.eps.surrey.ac.uk/savee/" style="border-left:none;">Home</a> </li>
    <li>  <a href="http://kahlan.eps.surrey.ac.uk/savee/Introduction.html">Introduction</a>   </li>
    <li> <a href="http://kahlan.eps.surrey.ac.uk/savee/Database.html">Database</a> </li>
    <li> <a href="http://kahlan.eps.surrey.ac.uk/savee/Evaluation.html">Evaluation</a> </li>
    <li> <a href="http://kahlan.eps.surrey.ac.uk/savee/References.html">References</a> </li>
    <li> <a href="http://kahlan.eps.surrey.ac.uk/savee/Download.html">Download</a> </li>
  </ul>
</div>

<div id="content" class="container_12 rounded">

  <div class="grid_12"><!-- InstanceBeginEditable name="MainContent" -->
      <h2><font color="blue">Abstract</font></h2>
    <p>Surrey Audio-Visual Expressed Emotion (SAVEE) database has been 
recorded as a pre-requisite for the development of an automatic emotion 
recognition system. 
The database consists of recordings from
4 male actors in 7 different emotions, 480 British English utterances
in total. 
The sentences were chosen from the standard
TIMIT corpus and phonetically-balanced for each emotion. 
The
data were recorded in a visual media lab with high quality
audio-visual equipment, processed and labeled. 
To check the
quality of performance, the recordings were evaluated by 10
subjects under audio, visual and audio-visual conditions. 
Classification
systems were built using standard features and classifiers
for each of the audio, visual and audio-visual modalities,
and speaker-independent recognition rates of 61%, 65% and
84% achieved respectively.</p>
    <hr>

    <h2><font color="blue">Conclusions</font></h2>
    <p>We have recorded an audio-visual database of expressed emotions
with six basic emotions and neutral. 
The database consists
of phonetically-balanced TIMIT sentences uttered by 4 English
actors with a total size of 480 utterances. 
The database was evaluated
by 10 subjects with respect to recognizability for each of
the audio, visual and audio-visual data. 
The subjective evaluation
results show higher classification accuracy for the visual
data compared to the audio, and the overall performance improved
by combining the two modalities. 
A reasonably high
classification accuracy was achieved in speaker-dependent and
speaker-independent experiments on the database, which follow
a similar pattern of emotion classification results as that by human
evaluators, i.e. the visual data performed better than the audio
and the overall performance improved for the audio-visual
combined. 
Human evaluation and machine learning experimental
results show the usefulness of this database for research in
the field of emotion recognition.</p>
    <hr>


    <h2><font color="blue">Acknowledgments</font></h2>
    <p>We are thankful to Kevin Lithgow, James Edge, Joe Kilner, Darren
Cosker, Nataliya Nadtoka, Samia Smail, Idayat Salako, Affan Shaukat
and Aftab Khan for help with the data capture, evaluation and as 
subjects,
to James Edge for his marker tracker, to Adrian Hilton for use of
his 3dMD equipment, to Sola Aina for help with the description of 
phonetic symbols, and to the University of Peshawar (Pakistan) and CVSSP
 at the University of Surrey (UK) for funding.</p>

  <!-- InstanceEndEditable --></div>
  <div class="clear"></div>
</div>
<div id="footer" class="container_12 topborder">
  <div class="grid_6" style="text-align:left;"><a href="http://www.surrey.ac.uk/">University of Surrey</a> | 
<a href="http://www.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Register.html">Register</a> | 
<a href="mailto:p.jackson@surrey.ac.uk?subject=SAVEE">Contact Us</a>
<!-- <a href="http://personal.ee.surrey.ac.uk/Personal/P.Jackson/">Contact Us</a> -->
 </div>
</div>
<div id="credit" class="container_12">


  <!-- The following link and credit cannot legally be altered or removed without a valid website license key purchased from http://www.justdreamweaver.com/templates/license.html. License keys are only $19.99 and once purchased you are free to remove or alter the link. -->

<div class="grid_12">
Last update: 2 April 2015
<br>
Authors: Philip Jackson and Sanaul Haq
<br>
Designed by <a href="http://www.justdreamweaver.com/dreamweaver-templates.html" target="_blank">JustDreamweaver.com</a>

</div>
</div>


</body><!-- InstanceEnd --></html>